---
title: CS2106 notes
tags: Module, CS2106
---

# Lecture 1: Introduction to OS

## Brief history of OS

- No OS
- Batch OS
  - Execute user program (job) one at a time
  - CPU idle when performing IO
- Time-sharing OS
  - terminals
  - user job scheduling (illusion of concurrency)
  - memory management
  - **virtualization** of hardware

## Motivations of OS

- Abstraction
  - hide low level details
  - *efficiency and portability*
- Resource allocator
  - for better utilization of resources
- Control program
  - prevent errors and improper use
  - provide security and protection

## OS Structure

![](https://i.imgur.com/BOE1p4c.png)

- Kernel mode: have complete access to all **hardware** resources
- User mode: ~limited

Ways to structure an OS:

- Monolithic
  - Pros: well understood; good performance
  - Cons: highly coupled; very complicated
  - ![](https://i.imgur.com/uuKlF6D.png)
- Microkernel
  - Only provides basic and essential facilities
    - Inter-process communication
    - Address space management
    - Thread management
  - Pros: robust&extendable; isolation of kernel from high level services
  - Cons: poorer performance
  - ![](https://i.imgur.com/n2ngtSN.png)

## Virtual machines

### Definition

- a software emulation of hardware
- virtualization of underlying hardware

Also known as **hypervisor**

- Type 1 hypervisor
  - runs directly on hardware
  - ![](https://i.imgur.com/rb2Y64N.png)
- Type 2 hypervisor
  - runs in host OS
  - ![](https://i.imgur.com/xRY6Mq7.png)

# Lecture 2: Process abstraction

Definition: a dynamic **abstraction** to describe an **executing** program (information required to describe a **running program**)

- Memory context
  - code (text), data
- Hardware context
  - registers (or GPR, general purpose registers)
  - PC (program counter, a special register)
- OS context
  - process properties
- resources used

## Memory context: function call

Important steps:
1. setup parameters
2. transfer control to callee
3. setup local variables
4. store result (if applicable)
5. return control to caller

### Stack memory

Definition: the new memory region to store information about **function invocation**

Content:
- return address of the caller (return PC)
- arguments for the function
- local variables
- saved SP (stack pointer)
- saved FP (frame pointer)

Frame pointer

The frame pointer points to a **fixed location in a stack frame**.

Saved registers

Register spilling
- when GPRs are exhausted
- use memory to temporarily hold GPR value
- restore GPR value from memory afterwards
- a function can do so before the function starts, and restore those registers afterwards

#### Function call convention

* On executing function call:
  * Caller: Pass arguments with registers and/or stack
  * Caller: Save Return PC on stack
* Transfer control from caller to callee
  * Callee: Save registers used by callee. Save old FP, SP
  * Callee: Allocate space for local variables of calleeon stack
  * Callee: Adjust SP to point to new stack top
* On returning from function call:
  * Callee: Restore saved registers, FP, SP
* Transfer control from calleeto caller using saved PC
  * Caller: Continues execution in caller

**Just an example!!**

## Memory context: dynamic allocated memory

![](https://i.imgur.com/z65ADI1.png)

- size not known during compilation 
  - cannot be stored in **Data** region
- no definite deallocation timing
  - no **Stack** region (stack must be in LIFO order, it doesn't support random order of removal)

## OS context: Process ID and process state

### Process state & state transition

![](https://i.imgur.com/ZppZV8K.png)

Global view:

With k CPU(s)
- <= k processes in *running* state
- <= k transition(s) at a time (conceptually 1 transition at a time on 1 CPU)
- Different processes may be in different states

### Queuing model of 5-state transition

![](https://i.imgur.com/5RhAPIy.png)

**Note:** the "queue" is not a real queue (i.e. not necessarily FIFO).

### Process table and process control block (PCB)

![](https://i.imgur.com/KEQqkVr.png)

## Process interaction with OS

### System calls

#### Unix system call in C/C++

* Can be called almost directly
  * function wrapper (similar to alias)
    * e.g. `getpid()`
  * function adapter
    * e.g. `printf()`

#### General syscall mechanism

1. User program invokes the library call (Using the normal function call mechanism as discussed)
2. Library call (usually in assembly code) places the system call number in a designated location (e.g. Register)
3. Library call executes a special instruction to switch from user mode to kernel mode (That instruction is commonly known as **TRAP**)
4. Now in kernel mode, the appropriate system call handler is determined using the system call number as index. (This step is usually handled by a **dispatcher**)
5. System call handler is executed
6. System call handler ended
* Control return to the library call
* Switch from kernel mode to user mode
7. Library call return to the user program via normal function return mechanism

Basically:

call library function 
-> setup syscall number 
-> invoke **TRAP** syscall 
-> determine syscall handler (in kernel mode) 
-> syscall handler handles the request 
-> switch from kernel mode to user mode, control return to library call 
-> library call returns

### Exception and interrupt

Exception
* from executing a machine level instruction
  * e.g. arithmetic errors, memory accessing errors
* is **synchronous**
* Effect
  * execute an **exception handler**
  * similar to a forced function call

Interrupt
* from external events
  * e.g. keyboard interruption
* is **asynchronous**
* Effect
  * program execution is **suspended**
  * execute an **interrupt handler**

## Process management

### Process abstraction in Unix

* Identification
  * PID
* Information
  * process state:
    * running, sleeping, stopped, **zombie**
    * parent PID
    * cumulative CPU time
  * `ps` to show process status
* Creation
  * `fork`
    * ![](https://i.imgur.com/IoLb9Df.png)
    * Child process is a duplicate of the current executable image
      * same code, same address space
      * data is **copied** from the parent (**NOT** shared)
    * Child process differs from parent in
      * pid
      * ppid
      * return value of `fork()` - child returns 0
  * `exec`
    * `execl()` syscall
      * replace current executing process image with a new one
      * only "code replacement", pid and other information still intact
      * ![](https://i.imgur.com/i18PMFX.png)
  * `fork() + execl()`
    * spawn off a child process to perform a task through `exec()`
    * parent process is still intact to accept another request
  * The master process
    * `init`, with pid=1, created in kernel at boot up time
    * watches for other processes and respawns where needed
* Termination
  * `exit`
    * ![](https://i.imgur.com/CdIZgkR.png)
    * `status` is returned to parent process (to be received by `wait()`)
    * 0 means normal exit, other values means abnormal
    * it does **NOT** return
  * Most system resources are released on exit
  * Not releasable:
    * PID & status - for parent-children sync
    * Process accounting info: e.g. CPU time
    * Process table entry (or PCB) **may be** still needed
  * Thus creates **zombie process**
    * cannot completely remove its info (since the parent may `wait()` it)
    * **CANNOT KILL ZOMBIE**
  * Implicit exit
    * return from `main()`
* Parent-child synchronization
  * `wait`
    * ![](https://i.imgur.com/kFszTuQ.png)
    * blocks until **at least one** child process terminates
    * cleans up the remainder of child processes
      * things that are not releasable by `exit()`
      * kill zombie process
  * `waitpid()` - wait for a specific child process
  * `waitid()` - wait for any child process to change status

#### Zombie process (2 cases)

1. Parent process terminates before child

* `init` becomes "pseudo" parent of the child process
* child termination sends signal to `init`, `init` calls `wait()` to do the cleanup

2. Child process terminates before parent, but parent didn't call `wait`

becomes zombie process!

#### Process diagram in Unix

![](https://i.imgur.com/uYNYp8E.png)

#### Implementation issues

##### Implementing `fork()`

1. Create address space of child process
2. Allocate `p'` = new PID
3. Create kernel process data structures
(e.g. Entry in Process Table)
4. Copy kernel environment of parent process
(e.g. Priority (for process scheduling))
5. Initialize child process context:
`PID` = `p'`, `PPID` = `parentid`, `CPU time` = 0
6. **Copy memory regions from parent**
  * Program, Data, Stack
  * Very expensive operation that can be optimized
    * Copy on write
      * Only duplicate a “memory location” when it is written to
      * Otherwise parent and child share the same “memory location”
      * (Copied by "pages", will be covered later)
7. Acquires shared resources:
Open files, current working directory etc
8. Initialize hardware context for child process:
Copy registers, etc. from parent process
9. Child process is now ready to run:
add to scheduler queue

address space -> kernel context -> process context -> memory context -> hardware context

#### Modern take on `fork()`

# Lecture 3: Process scheduling

## Concurrency vs. parallelism

* concurrency is a logical concept
* it could be virtual parallelism
  * parallelism must run on multiple physical processors
* concurrency includes parallelism

## Scheduling in OS

* Scheduling problem
  * If ready-to-run process is more than available CPUs, which should be chosen to run?
* Scheduler
  * Part of the OS that makes scheduling decision
* Scheduling algorithm
  * The algorithm used by scheduler

### Process behavior

* CPU activity
* IO activity

### Processing environment

1. Batch Processing:
No user: No interaction required, No need to be responsive
2. Interactive(or Multi-programming):
* With active user interacting with system
* Should be responsive, consistent in response time
3. Real time processing:
* Have deadline to meet
* Usually periodic process

### Criteria for scheduling algorithms

* Fairness
  * fair share of CPU time
    * per process
    * per user
  * **NO starvation**
* Balance
  * high utilization rate on all parts

### Scheduling for batch processing

**Non-preemptive** (cooperative) scheduling algorithms are predominant in batch processing systems. (i.e. A process stayed scheduled (in running state) until it blocks or give up the CPU voluntarily.)

* Criteria for batch processing
    * Turnaround time
        * total time taken (i.e. arrival-finish time)
    * Waiting time
        * time spent waiting for CPU
        * = turnaround time - CPU time
    * Throughput
        * #of tasks finished per unit time
    * CPU utilization
        * % of time CPU working on a task
* First-Come First Served (FCFS)
    * Pick the first task in queue to run until the task is done OR the task is blocked
    * Blocked task is removed from the FIFO queue
        * When it is ready again, it is placed at the back of queue
    * Pros
        * Guaranteed to have no starvation
    * Shortcoming
        * long job at the front makes small jobs wait
        * *Convoy effect*
            * ![](https://i.imgur.com/HKxC7Fg.png)
* Shortest Job First (SJF)
    * Need to know *total CPU time* in advance
        * Exponential average
            * ![](https://i.imgur.com/rNSoiHw.png)
    * Pros: (given a fixed set of tasks)
        * Minimizes average waiting time
    * Cons:
        * Starvation is possible (long job may never get a chance)
* Shortest Remaining Time Next (SRT)
    * SRT is **preemptive**


### Scheduling for interactive systems

**Preemptive** scheduling algorithms:
* A process is given a fixed time quota to run
  * possible to block or give up early
* At the end of the time quota, the running process is suspended
  * Another process get picked if available

* Criteria for interactive OS
    * response time
        * time between request and response from OS
    * predictability
        * variation in response time
* Periodic scheduler
    * Why?
        * scheduler is preemptive
        * to ensure good response time
    * How?
        * *timer interrupt*
            * interrupt that goes off periodically
            * hardware clock based
            * OS ensures *timer interrupt* cannot be intercepted by other programs
        * *timer interrupt* invokes scheduler
    * Timer & time quantum
        * ![](https://i.imgur.com/cXW8sWx.png)
* Round Robin (RR)
    * Preemptive version of FCFS
    * ![](https://i.imgur.com/NMGIji7.png)
    * Pros:
        * response time is guaranteed
            * Given $n$ tasks and a quantum $q$
            * The time before a task get CPU is no more than $(n-1) * q$
    * Cons:
        * choice of time quantum is important
            * longer: better CPU utilization, worse response time
            * shorter: better response time, more CPU overhead (scheduler needs CPU time)
* Priority based
    * Assign priority to tasks, execute the task with the highest priority
    * Variants
        * Preemptive version
        * Non-preemptive version
    * Cons: 
        * low priority process can starve
            * exists on both preemptive and non-preemptive versions
            * Possible solutions:
                * Decrease the priority of currently running process after every time quantum
                * or Give the current running process a time quantum
                    * this process is not considered in the next round of scheduling
        * Priority inversion
            * lower priority task preempts higher priority task
            * ![](https://i.imgur.com/OrxoTEa.png)
        * Generally, it is hard to guarantee or control the exact amount of CPU time given to a process using priority
* Multi-level feedback queue (MLFQ)
    * Rules
        * Basic rules
            * If Priority(A) > Priority(B) -> A runs
            * If Priority(A) == Priority(B) -> A and B runs in RR
        * Priority changing rules
            * new job -> highest priority
            * if job used up its time quantum -> priority reduced
            * if job gives up or blocks before its time quantum -> priority retained
    * Pros
        * Minimizes both:
            * Response time for IO bound processes
            * Turnaround time for CPU bound processes
    * Cons
        * To abuse the algorithm
            * give up at $0.99 * t_{time quantum}$
            * to rectify: unfixed time quantum?
* Lottery scheduling


# Lecture 4: Inter-process communication

## 4.1 Shared memory

- How?
    - p1 **creates** a shared memory region *M*
    - p2 attaches memory region *M* to its own *memory space*
    - p1 and p2 now communicates via *M*
- OS is **only** responsible for
    1. creating the shared memory
    2. attaching *M* to p2's memory space
- OS is not responsible for releasing *M*
    - either p1 or p2 can initiate the releasing process
- Pros
    - Efficient: minimal OS intervention
    - Ease of use: behaves like normal memory
- Cons
    - Synchonization
    - Harder implementation
- Unix usage
```C
int main() {
    int shmid, *shm;

    // CREATE shared memory region
    shmid = shmget( IPC_PRIVATE, 40, IPC_CREAT | 0600 );
    if(shmid == -1) { exit(1); // Failed to CREATE }

    // ATTACH to the shared memory region
    shm = (int*) shmat( shmid, NULL, 0 );
    if(shm == (int*) -1) { exit(1); }
    // From now onwards, shm can be used as a normal int array: shm[0]

    shmdt( (char*) shm ); // destory
    shmctl( shmid, IPC_RMID, 0); // detach
}
```
## 4.2 Message passing

Use system calls to send and receive messages.

![](https://i.imgur.com/jtVQgmu.png)


- `Msg` have to be stored in **kernel memory space**
- Every send/receive goes through OS by a syscall

### Additional properties

- Naming
    - Indirect communication
        - `msg` is sent to and received from a *message storage* (i.e. mailbox or port)
            - One mailbox can be shared among processes
            - No receiver is specified, sent to a mailbox
    - Direct communication
        - Sender/Receiver of message explicitly name the other party
            - One link per pair of communicating processes
            - Need to know the identity of the other party
- Synchronization
    - Blocking primitives (sync)
        - send(): blocked until received
        - receive(): blocked until message arrived
    - Non-blocking primitives (async)

### Pros and cons

- Pros
    - portable
    - easier synchronisation
- Cons
    - inefficient
    - harder to use: limited size and/or format

## 4.3 Unix pipes

Unix's three communication channels: `stdin`, `stdout` and `stderr`

![](https://i.imgur.com/PUpmQcd.png)


### Semantics

- Behavior
    - Like anonymous file
    - FIFO - can only read data in order
- Like a circular bounded byte buffer with **implicit synchronization**
    - writer waits when pipe is full
    - reader waits when pipe is empty
- Variants
    - multiple readers/writers
    - half-duplex or full-duplex (i.e. unidirectional or bidirectional)

### Unix system call

```C
#include <unistd.h>
int pipe( int fd[] );
```

Return

- 0 for success, !0 for error
- `fd[0]` is file descriptor for reading end, `fd[1]` for writing end

![](https://i.imgur.com/bV87L8F.png)

- For writer
    - close read end
    - write to write end
    - close write end
- For reader
    - close write end
    - read from read end
    - close read end

**Redirect std channels**

- `dup`
- `dup2`

## 4.3 Unix Signal

- A form of inter-process communication
    - An **asynchronous** notification regarding an event sent to a process/thread
- The recipient of the signal must handle the signal by:
    - A default set of handlers OR
    - User supplied handler (only applicable to some signals)
- Common signals in Unix:
`Kill`, `Stop`, `Continue`, `Memory error`, `Arithmetic error`, etc….

Use `signal(SIGNAL, handler)` function to register our own handler replacing the default handler.

```C
void myOwnHandler(int signo){
    if (signo== SIGSEGV){
        printf("Memory access blows up!\n");exit(1);
    }
}

if (signal(SIGSEGV, myOwnHandler) == SIG_ERR)
    printf("Failed to register handler\n");
```

# Lecture 5: Process alternative - threads

## Motivation

- Process is expensive in
  - created using `fork()`
    - duplicate memory space
    - duplicate most of the context
  - context switch
- Inter-process communication is hard
  - independent memory space

## Basic idea

- A traditional process has a single *thread of control*
- We add more threads of control to the same process
  - multiple parts of the program is executed concurrently

## Comparison with process

### What's shared and what's not

- A single process can have multiple threads - multithreaded process
- Threads in the same process share
  - **Memory context**: text, data, **heap**
  - **OS context**: process ID, files, etc.
- Threads don't share
  - Identification (e.g. thread ID)
  - Hardware context
    - Registers
    - Stack

### Thread switch

- For a (process) context switch, it involves switching
  - OS context
  - Hardware context
  - Memory context
- For a thread switch, it only involves
  - Hardware context
    - registers
    - stack (when switching context we don't actually rewrite the stack memory, we simply move the FP and SP registers. That's why it's counted towards hardware context instead of memory context)

### Pros and cons

* Pros
  * less resources
  * easier resource sharing
    * since they share the heap, no additional communication mechanism is needed
  * responsive
  * scalability
* Cons
  * System call concurrency
    * parallel syscalls are possible
    * `MT-Level` indicates how safe multi-threading is
  * Process behavior
    * `fork()` doesn't duplicate threads in a process
    * A single thread executing `exit()` won't exit the entire process

## Thread models (Skipped)

## POSIX threads

### Basics of `pthread`

- Header file
  - `#include <pthread.h>`
- Compilation
  - `gcc XXX.c -lpthread`
- Useful data types
  - `pthread_t`: thread ID (TID)
  - `pthread_attr`: attributes of a thread
- Creation syntax
  - ![](https://i.imgur.com/Q7PoR5t.png)
- Termination syntax
  - ![](https://i.imgur.com/1zcGqpy.png)

```C
void* sayHello( void* arg)
{
  printf("Just to say hello!\n");
  pthread_exit( NULL );
}
int main()
{
  pthread_t tid;
  pthread_create( &tid, NULL, sayHello, NULL );
  printf("Thread created with tid%i\n", tid);
  return 0;
}
```

(Skipped a lot during the lecture)

# Lecture 6: Synchronization

## Race condition

Execution outcome depends on the order in which the *shared resource* is accessed / modified.

* Key points to a race condition
  * multiple processes execute concurrently in **interleaving** fashion
  * **share a modifiable resource**
* Why race condition may result in bad behavior?
  * due to **unsynchronized access to a shared modifiable resource**

## Critical section - solution to race conditions

At any point in time, **only one** process can execute in the critical section, preventing other processes from entering the same critical section.

### Properties of a correct CS impl

* Mutual exclusion (mutex)
  * If process $P_i$ is executing in critical section, all other processes are prevented from entering the critical section.
* Progress
  * If no process is in a critical section, one of the waiting processes should be granted access.
* Bounded wait
  * After process $P_i$ request to enter critical section, there exists an upper bound of number of times other processes can enter the critical section before $P_i$.
* Independence
  * Process not executing in critical section should never block other process.

### Symptoms of incorrect synchronization

* Deadlock
* Livelock
* Starvation

### Assembly level impl - `TestAndSet`

`TestAndSet Register, MemoryLocation`

* Behavior
  * load content at `MemoryLocation` into `Register`
  * store 1 into `MemoryLocation`
* Usage
  * ![](https://i.imgur.com/ZBZsBkD.png)
* Cons
  * busy waiting

**Note**: the two steps are performed as a **SINGLE** machine operation (i.e. atomic), so that no changes to the content of `MemoryLocation` will happen between loading the content and storing 1 back into that location.

```C
void enter_region() {
  TSL $t0, $lock // reads $lock to $t0 and set $lock to be 1
  CMP $t0, 0 // compares $t0 with 0
  JNE enter_region // loop back is lock is already 1
  return; // else return, meaning we're already in the CS
}

void leave_region() {
  MOV $lock, 0
  return;
}
```

### High level language impl

* Attempt 1: a `lock` variable
  * ![](https://i.imgur.com/zsWeBT9.png)
  * violates *mutual exclusion*
    * two processes may enter CS one after another and both be present in the CS
  * Can't be fixed by preventing context switching
    * ![](https://i.imgur.com/ifH1tWv.png)
    * OS doesn't allow disabling scheduler interrupts
      * otherwise buggy CS would stall the whole system
* Attempt 2: a `turn` variable
  * ![](https://i.imgur.com/wexJmDW.png)
  * solves *mutex* problem
  * violates *independence*
    * If p1 hits `while(Turn != 1)` before p0 enters and exits CS
    * p1 has to wait for p0 to release the lock, which means a process not executing in CS (p0) is blocking another process (p1)
* Attempt 3: two `want` variables
  * ![](https://i.imgur.com/DaFNtGz.png)
  * solves *independence* problem because if `Want[0] != 1` then p1 will enter the CS
  * violates *progress*
    * i.e. *deadlock* may happen!
    * `Want[0]=1` -> `Want[1]=1` -> both processes blocked in the while loop

#### Peterson's algorithm

* (Basically a combination of attempt 2 and 3)
* Assume that `Turn` is an **atomic** operation
  * blocked only when it is not my turn **AND** the other wants the resource
  * `Turn` ensures progress
    * i.e. not deadlocked because of `Turn`
    * `Turn` can be either 0 or 1, either way one process is guaranteed to progress
  * `Want[a] && Turn==a` ensures mutex
    * If `!(Want[1] && Turn==1)`
      * case 1: `Want[1]==0`
        * process p1 hasn't reached CS yet
        * if it reaches CS and p0 hasn't exited CS yet
          * `Want[0]==1` because p0 set it up and hasn't set it back to 0
          * `Turn[0]==0` because p1 set it
        * if it reaches CS and p0 finishes
          * p1 gets into CS because `Want[0]` is set to 0 by p0
      * case 2: `Turn==0`
        * It must be the case where p1 sets `Turn` to be 0
        * `Want[0]` is already 1
        * p1 is blocked by the while loop
  * independent

![](https://i.imgur.com/M9sYhIV.png)

* Cons
  * busy waiting
  * too low level, not general

#### Problem with busy waiting: *priority inversion*

Assume `H` gets to run whenever it's ready and `L` is of low priority:

If `L` enters the CS, while `L` is still in the CS, `H` finishes its IO task and gets ready. If `H` busy waits, because of the scheduling rule, `L` never gets its chance to leave the CS, thus `H` is blocked by `L` because of busy waiting.

### High level abstraction - Semaphore

#### Two atomic operations: `Wait()` and `Signal()`

* `Wait(S)` or `Down(S)`
  * if S<=0, blocks
  * (after waken up, ) decrease S
* `Signal(S)` or `Up(S)`
  * increment S
  * wakes up one sleeping process if any

#### Properties

* Given $S_{initial} >= 0$
  * $S_{current} = S_{initial} + {Count}_{signal(S)} - {Count}_{wait(S)}$

#### General and binary semaphores

Mimic general (or counting) semaphore using binary semaphores:

```C
GS = 3;
wait(GS);
// Critical section
signal(GS);
```

```C
// Use two binary semaphores
countLock;
sectionLock;

int count = 3;

wait(countLock);
  count--;
  if( count <= 0 ) {
    wait(sectionLock);
  }
signal(countLock);

// Critical Section

wait(countLock);
  count++;
  if( count > 0 ) {
    signal(sectionLock);
  }
signal(countLock);

```

#### Correctness of semaphore

* Mutual exclusion
  * ![](https://i.imgur.com/eMPk8UC.png)
* No deadlock
  * ![](https://i.imgur.com/0bh6gOt.png)

Deadlock is still possible with incorrect use of semaphores:

![](https://i.imgur.com/hUbzHpR.png)

#### Two use cases of semaphores

* Mutex
  * a binary semaphore
  * `wait(mutex)` as `enter_CS`
  * `signal(mutex)` as `leave_CS`
  * ensures only one process is in the CS
* Synchronization
  * guarantees that certain event sequences do or do not occur
  * `empty` semaphore in *producer consumer*: ensures producer won't produce when full
  * `full` ensures consumer won't consume when empty

### Other high level abstractions

* Semaphore is powerful - no known unsolvable synchronization problem using semaphore
* Conditional variable
  * allow a task to wait for a certain *event* to happen
  * has the ability to *broadcast* - wakes up all waiting tasks
* Monitor

## Classical synchronization problems

### Producers consumers

* A buffer with fixed length K
* Producers can only produce when buffer is not full
* Consumers can only consume when buffer is not empty

#### Busy waiting

![](https://i.imgur.com/XSHygGY.png)

#### Blocking

![](https://i.imgur.com/WcyuKfQ.png)

* `wait( notFull )` : Forces producers to go to sleep
* `wait( notEmpty )`: Forces consumers to go to sleep
* `signal( notFull )`: 1 consumer wakes up 1 producer
* `signal( notEmpty )`: 1 producer wakes up 1 consumer

My attempt:

```C
while (TRUE) {
  wait(countLock);
  if ( count < K ) {
    wait(bufLock);
    produce item;
    signal(bufLock);
    count++;
  }
  signal(countLock);
}
```

```C
while (TRUE) {
  wait(countLock);
  if( count > 0 ) {
    wait(bufLock);
    consume item;
    signal(bufLock);
    count--;
  }
  signal(countLock);
}
```

### Readers writers

* readers and writers share a data structure $D$
  * reader retrieves info from $D$
  * writer modifies info from $D$
  * reader can access with other readers
  * writer must have **exclusive** access to $D$

![](https://i.imgur.com/UopwQ3g.png)

* Starvation on the writers
  * there's a more complicated solution without starvation

My attempt on no starvation version:

Reader

```C
wait(noWriter);
wait(mutex);
if(count == 0) wait(isEmpty);
count = count + 1;
signal(mutex);

read();

wait(mutex);
count = count - 1;
if(count == 0) signal(isEmpty);
signal(mutex);
```

Writer

```C
wait(isEmpty);
write();
signal(isEmpty);
signal(noWriter);
```

### Dining philosopher

#### Tanenbaum solution

```C
#define N 5
#define LEFT ((i+N-1) % N)
#define RIGHT ((i+1) % N)
#define THINKING 0
#define HUNGRY 1
#define EATING 2

int state[N];
Semaphore mutex= 1;
Semaphore s[N];

void philosopher( int i ){
  while (TRUE){
    Think( );
    takeChpStcks(i);
    Eat( );
    putChpStcks(i);
  }
}

void takeChpStcks( i)
{
  wait(mutex);
  state[i] = HUNGRY;
  safeToEat(i);
  signal(mutex);
  wait( s[i] );
}

void safeToEat( i)
{
  if( (state[i] == HUNGRY) &&
    (state[LEFT] != EATING) &&
    (state[RIGHT] != EATING) ) {
    state[i] = EATING;
    signal( s[i] );
  }
}

void putChpStcks( i)
{
  wait(mutex);
  state[i] = THINKING;
  safeToEat(LEFT);
  safeToEat(RIGHT);
  signal(mutex);
}
```

#### Limited eater

If at most 4 philosophers are allowed to sit at the table, then deadlock is impossible: we have a semaphore `seats` with initial value 4

![](https://i.imgur.com/WDFzHVz.png)

## Synchronization implementations

### POSIX semaphore

* header file: `#include <semaphore.h>`
* `gcc XXX.c -lrt` "real time library"

### `pthread` mutex and conditional variables

* `pthread_mutex`
  * binary semaphore
  * lock: `pthread_mutex_lock()`
  * unlock: `pthread_mutex_unlock()`
* Conditional variables (`pthread_cond`)
  * Wait: `pthread_cond_wait()`
  * Signal: `pthread_cond_signal()`
  * Broadcast: `pthread_cond_broadcast()`

# Lecture 7: Memory abstraction

## Basic of memory

* Hardware
  * A **contiguous memory region**: an interval of **consecutive** addresses
* Memory usage of process
  * Text/Data/Heap/Stack
  * Two types of data in process - both may grow/shrink during the execution
    * Transient data: parameter, local variable
    * Persistent data: global variable, constant variable, dynamically allocated memory
* Role of OS
  * Binding of memory address
  * Five tasks of OS:
    * Allocate/manage/protect memory space
    * Provide system calls for memory operations
      * Manage memory space for **internal use**

## Memory abstraction

### Without abstraction

* Assign **actual physical address** during **compilation** time
* Pros
  * memory access is straightforward, no conversion/mapping is needed
* Cons
  * hard to protect memory space (what happens if the same compiled binary is executed twice? they will access the same memory addresses...)

### Fix 1: address relocation

* Recalculate the memory references when the process is loaded into memory (i.e. add an **offset** to every memory access)
* Problem:
  * Slow **loading** time (not running time, the code is translated when it's loaded)
  * Not easy to distinguish memory reference from normal integer constant

### Fix 2: `Base` + `Limit` registers

* All memory addresses are compiled to `Base + offset`
* and is checked against `Limit` to protect *memory space integrity*
* `Base` register is initialized at loading time
* Problem
  * every memory access incurs an addition and a comparison

### Actual fix: logical address

* Logical address is how a process views its memory space
  * Each process has a **self-contained**, **independent** logical memory space
* Keep a mapping between logical address and physical address

## Contiguous memory management

Why memory management? 

* To support multi-tasking
    * allow multiple processes in physical memory at the same time
    * switch context among processes
* When the physical memory is full, free up memory by
    * removing terminated processes
    * swapping blocked process to **secondary storage**

Assumption:

1. Each process occupies a contiguous memory region
2. The physical memory is large enough to contain one or more processes with complete memory space

### Memory partition

Definition: The contiguous memory region allocated to a single process

* Schemes for allocating partitions
    * Fixed-size partition
        * Pros: easy to manage and fast to allocate
        * Cons: 
            * partition size needs to be large enough to contain the largest process
            * **internal fragmentation** (when a process does not occupy the whole region)
    * Variable-size partition (dynamic partitioning)
        * Partition is created based on the actual size needed by the process
        * OS keeps track of occupied and free memory regions
            * **merging and splitting** becomes necessary
        * Pros: flexible and no internal fragmentation
        * Cons:
            * need to maintain more information in OS
            * take more time to locate where to put a process
            * **external fragmentation**: may have lots of holes (hole - free memory space), can be merged to larger holes

#### Dynamic partitioning

* Allocation algorithms: to locate partition of at least size `N`
    * Search for a whole with size M > N
        * First fit
        * Best fit
        * Worst fit
    * Split the whole into two parts: N and M-N
* Merging and compaction
    * merge: when freeing an occupied partition, merge with adjacent holes if possible
    * compaction: move occupied partitions around to create consolidate holes
        * time consuming, can't do often
* Implementation
    * Linked list: used to keep partition info
        * node: status, start address, length, pointer to next node
* Buddy system
  * ![](https://i.imgur.com/JnHoUB6.png)
  * Implementation
    * Let $2^k$ be the largest allocatable block size
    * Keep an array `A[0...k]`
      * each element in the array is a **linked list** storing the **starting addresses** of blocks of size $2^n$
    * Algorithm: to allocate a block of size $N$
      1. find the smallest $S$ such that $2^S >= N$
      2. check `A[S]`
      3. if there is a free block in `A[S]`, remove the block from the free block list
      4. if there is no free block in `A[S]`
      5. find the smallest $R$ from $S+1$ to $K$ such that there is one free block `B` in `A[R]`
      6. repeatedly split `B` in half: `A[S...R-1]` will have a new block
      7. go to step 2
    * Algorithm: to deallocate a block `B` of size $2^A$
      1.  check `A[S]`
      2.  if buddy of `B` exists in `A[S]`, remove `B` and its buddy from `A[S]` and merge them to a larger block (i.e. `A[S+1]` will have a new free block), go back to step 1 where now `B` is replaced with the 2 times larger block `B'`
      3.  else insert `B` into `A[S]`
    * Determine buddies
      * two blocks B and C are buddy of size S, if
        * The Sth bit of Band C is a complement (i.e. a 0 and a 1)
        * The leading bits up to Sth bit of Band Care the same

# Lecture 8: Disjoint memory schemes

## Paging scheme

### Basic idea

* Frame
  * physical memory is split into **frames** of fixed size
* Page
  * logical memory is split into **pages** of the same size
* Pages are loaded into **any available** physical frame
  * logical memory - still contiguous
  * physical memory - can be disjoint
  * Lookup mechanism
    * a mapping from logical page # to physical frame #
    * known as **page table**
  * Logical address translation
    * $Address_{physical} = F * Size_{frame} + Offset$
      * $F$ - physical frame #
      * Offset - displacement from the beginning of a frame
    * Keep frame size as a power of 2
    * Keep page size the same as frame size
    * ![](https://i.imgur.com/mERtbYQ.png)
    * Procedure
      * determine how many bits are reserved for offset
      * without looking at the offset bits, translate the first (m-n) bits of the logical address (i.e. page number) to the first k bits of physical address (i.e. frame number)
      * concatenate two numbers

### Observations

* Paging removes **external fragmentation**
* Paging still has **internal fragmentation**
* Clear separation of logical and physical address space
  * Allow great flexibility
  * Simple address translation

### Implementation

* Pure software
  * in each PCB (process control block), the OS stores the page table
  * Issues
    * requires two memory accesses for every memory reference (one for page table, one for actual memory access)
* Hardware support
  * **Translation Look-Aside Buffer (TLB)**
    * a cache of a few page table entries
    * for each memory reference, look up the TLB first
      * Entry found (TLB-Hit):
        * Frame number is retrieved to generate physical address
      * Entry not found (TLB-Miss):
        * Memory access to access the full page table
        * Retrieved frame number is used to generate physical address and update TLB
        * (overhead of filling TLB is ignored, meaning the total time for TLB-miss is $t_{TLB} + 2t_{memory}$)
    * TLB is part of the **hardware context**
      * TLB is flushed when a context switch happens
      * May have many TLB-misses to fill up the TLB when context is switched
      * Can prefill TLB with some code pages to reduce initial misses

### Protection

* Access right bits
  * Whether it is writable, readable, executable
  * E.g. page containing code should be executable, page containing data should be readable and writable etc
* Valid bit
  * whether a page is valid for this process to access
  * memory access is checked against the valid bit, out-of-range access is caught by the OS

### Page sharing

* Page table can allow several processes to share the same physical memory frame
  * Use the same physical frame number in the page table entries
* Possible usage:
  * Shared code page:
    * some code are being used by many processes, e.g. C standard library, system calls etc
  * Implement Copy-On-Write:
    * parent and child process can share a page until one tries to change a value in it
    * basically some entries in two processes page tables are pointed to the same physical frames until one of them make changes to these pages, then the OS copy the physical frame to another frame, and point that changed page to the new frame


## Segmentation scheme

### Basic idea

* Logical memory space = a collection of segments
* Each memory segment has
  * a name
  * a limit
* Segment is mapped to a **contiguous** memory region (segments can be disjoint from each other, but each segment is contiguous)
  * with a *base address* and a *limit*
* Memory reference = **segment name + offset**
  * ![](https://i.imgur.com/6fvnL7F.png)

### Implementation

* Logical address: `<SegID, Offset>`
* Address translation
  * use `SegID` to look up the table to find `(base, limit)`
  * physical address = `base + offset`
  * PA is checked against `limit` for valid access
* Hardware support
  * ![](https://i.imgur.com/azei2ix.png)

### Observations

* Pros
  * segments are independent from each other
    * can grow/shrink independently
    * can be protected/shared independently
* Cons
  * segmentation requires variable-sized contiguous memory regions
    * known as **external fragmentation**

## Segmentation with paging scheme

### Basic idea

* Each segment consists of several pages
  * i.e. each segment has a page table
* Segments grow/shrink by adding/removing pages from its page table

![](https://i.imgur.com/JIRoiln.png)

# Lecture 9: Virtual memory management

## Virtual memory

Some pages are stored in physical memory, some are stored in secondary storage.

### Implementation

* Memory resident bit
  * a new bit in the PTE (page table entry)
  * 1 means the frame # can be used to get physical address
  * 0 means a **page fault** if trying to access this page
* Page fault
  * When CPU tries to access non-memory resident page
      * OS need to bring a non-memory resident page into physical memory

![](https://i.imgur.com/zrk0yq0.png)
![](https://i.imgur.com/Ut0nBj4.png)

### Justification

* Thrashing
  * memory access results in *page fault* most of the time
  * since second storage access time is much slower than physical memory
  * memory references would be slow
* Locality principles
  * Temporal Locality: Memory address which is used is likely to be used again
  * Spatial Locality: Memory addresses close to a used address is likely to be used

### Summary

* Logical memory address is no longer restricted by physical memory size
* More efficient use of physical memory
  * Page currently not needed can be on secondary storage
* Allow more processes to reside in memory
  * Improve CPU utilization as there are more processes to choose to run

## Page table structure

Problems with huge page table

* High overhead
* **Fragmented page table**
  * Page table occupies several memory pages

### Direct paging

Keep all entries in a single table.

### 2-level paging

#### Basic idea

* Split the full page table into regions (i.e. smaller page tables)
* Only a few regions are used
  * As memory usage grows, new region can be allocated

#### Implementation

![](https://i.imgur.com/mAFjZur.png)

* Keep the size of the smaller page table the same as the size of a single frame/page
  * to prevent fragmented page tables
* Overhead = page directory + smaller page tables in use
  * compared with direct paging, 2-level paging only stored smaller in-use page tables

### Inverted page table

* Keep a single mapping of physical frame to `<pid, page#>`
  * `page#` is not unique among processes
    * as every process has a page table, every process will assume itself has the entire logical memory space
  * `pid + page#` can uniquely identify a memory page
* Entries of the inverted page table
  * are ordered by **frame number**
  * to look up page X for process P, need to loop up the entire table
* Pros: huge saving
* Cons: slow translation

## Page replacement algorithms

* When do we need to replace a page?
  * Suppose there is no free physical memory frame during a page fault:
  * Need to evict (free) a memory page
* When a page is evicted
  * clean = not modified -> no need to write back (to disk)
  * dirty = modified -> need to write back

### Evaluating a page replacement algorithm

Memory access time: $T_{access} = (1-p) * T_{mem} + p * T_{page fault}$ where $p$ is the probability of page faults.

Rule: Good algorithm should **reduce the total number of page faults**.

### Optimal page replacement (OPT)

* Replace the page that will not be used again for the longest period of time
* Guarantees minimum number of page faults
* Not achievable
  * need future knowledge
  * useful as a base for comparison

### FIFO

* Evict the oldest page
* Implementation
  * OS maintain a queue of resident page numbers
    * Remove the first page in queue if replacement is needed
    * Update the queue during page fault trap
  * Simple implementation - no hardware needed
* Problem
  * **Belady's Anomaly**
    * normally, as number of frame increases, the total number of page faults should decrease.
    * however for FIFO this might not be the case
  * Reason: FIFO doesn't exploit **temporal locality**

### LRU (least recently used)

* Evict the least recently used page
  * exploit the **temporal locality**
  * attempt to mimic OPT, doesn't suffer from *Belady's Anomaly*
* Implementation
  * Keep track of the "last used time" of every page
  * Approach A: counter
    * increment the counter for every memory reference
    * update the "time of use" field in the page table every time a page is referenced
    * replace the page with the smallest "time of use"
    * problem
      * need to search all pages to find the LRU
      * counter may overflow
  * Approach B: "stack"
    * Maintain a stack of page numbers
    * If page Xis referenced
      * Remove from the stack (for existing entry)
      * Push on top of stack
    * Replace the page at the bottom of stack
      * No need to search through all entries
    * Problems:
      * Not a pure stack: Entries can be removed from any where in the stack
      * Hard to implement in hardware

### Second-chance page replacement (CLOCK)

* Modified FIFO to give a second chance to pages that are accessed
* Each PTE now maintains a "reference bit":
  * 1 = Accessed, 0 = Not accessed
* Algorithm:
  1. The oldest FIFO page is selected
  2. If reference bit == 0: Page is replaced
  3. If reference bit == 1: 
    * Page is given a 2nd chance, reference bit cleared to 0 (page taken as newly loaded)
    * Next FIFO page is selected, go to Step 2
* Degenerate into FIFO algorithm when all pages has reference bit == 1

#### Implementation

![](https://i.imgur.com/0Xfm0oK.png)

## Frame allocation

### Simple approaches

* Equal allocation
  * every process gets the same # of frames
* Proportional allocation
  * process gets # of frames proportional to its size

### Local and global replacement

* Local replacement (assumed when discussing page replacement before)
  * Victim page are selected **among pages of the process that causes page fault**
  * Pros: performance is stable between multiple runs
  * Cons: If frame allocated (to the process) is not enough, it hinders the progress of a process
* Global replacement
  * Victim page can be chosen **among all physical frames**
  * Pros: Allow self-adjustment between processes
  * Cons:
    * Badly behave process can affect others
    * Unstable performance between runs

### Frame allocation and thrashing

![](https://i.imgur.com/R4nApld.png)

### Working set model

Defines Working Set Window Δ - an interval of time
$W(t,Δ)$ = active pages in the interval at time t
Allocate enough frames for pages in $W(t, Δ)$ to reduce possibility of page fault

# Lecture 10: File system introduction

## File system

File System provides:
* An abstraction on top of the physical media (direct access to storage media is **not portable**)
* A high level resource management scheme
* Protection between processes and users
* Sharing between processes and users

File system consists of: **files** and **directory** structures
* File: an abstract storage of data
* Directory: organization of files

### General criteria

* Self-contained
* Persistent
* Efficient

![](https://i.imgur.com/zy5BGNy.png)

## File system abstractions

### File

#### Basic definition
  * an ADT (abstract data type)
  * field: data & metadata
  * operations: later

#### File metadata

* ![](https://i.imgur.com/1zOY9Tb.png)
* Name
  * Different FS has different rules
  * Common rules
    * Length of file name
    * Case sensitivity
    * Allowed special symbols
    * File extension
      * Usual form `Name.Extension`
      * On some FS, extension is used to indicate file type
* Type
  * Each type has an associated set of operations, and possibly a specific program to process
  * Determine type of file
    * Windows: use **file extension**
    * Unix: use **embedded information**
      * usually stored at the beginning of the file as a *magic number*
  * Common file types
    * regular files
      * ASCII files
      * Binary files
    * directories
    * special files
* Operations
  * rename
  * change attributes
  * read attributes


#### File protection

* Types of access
  * Read:Retrieve information from file
  * Write:Write/Rewrite the file
  * Execute:Load file into memory and execute it
  * Append:Add new information to the end of file
  * Delete:Remove the file from FS
  * List:Read metadata of a file
* Permission bits
  * Classified the users into three classes:
    * Owner:The user who created the file
    * Group:A set of users who need similar access to a file
    * Universe:All other users in the system
  * ![](https://i.imgur.com/ghiL2IG.png)
* Access control list (ACL)
  * minimal ACL: same as permission bits
  * extended ACL: ![](https://i.imgur.com/3CqSdAP.png)

#### File data

* Structure
  * array of bytes
  * fixed length records
  * variable length records
* Access methods
  * sequential access
    * Data read in order, starting from the beginning
    * Cannot skip but can be rewound
  * random access
    * two ways of random access
      * `Read (Offset)`
      * `Seek (Offset)` - Unix and Windows uses
        * moves the cursor
        * then call `read()` to read the data at the cursor
  * direct access
    * used for file contains **fixed-length records**
    * allow random access to any record directly
    * useful for large amount of records (e.g. database)
    * degraded to random access when each record is a byte
* Operations
  * ![](https://i.imgur.com/SHXbjdV.png)

#### File operations

* As a system call
  * Provide protection, concurrent and efficient access
  * Maintain information
* Information kept for an opened file
  * file pointer
  * disk location
  * open count
* Organization of opened file information
  * System-wide open-file table:
    * One entry per unique file
  * Per-process open-file table:
    * One entry per file used in the process
    * Each entry points to the system-wide table

![](https://i.imgur.com/0rz4dzv.png)

* File sharing
  * use different file descriptors (can have two offsets)
    * ![](https://i.imgur.com/d93XTIv.png)
  * use the same file descriptor (share the same offset)
    * ![](https://i.imgur.com/8rFt2Ns.png)

## Directory

* Single-Level
  * ![](https://i.imgur.com/p44zulI.png)
* Tree-Structure
  * tree - every node (except for the root) has one and only one parent
  * ![](https://i.imgur.com/sHxPmrF.png)
  * methods to refer to a file
    * absolute pathname
    * relative pathname
* Directed Acyclic Graph (DAG)
  * ![](https://i.imgur.com/qELATW4.png)
  * Hard link: `ln`
    * limited to **file only**
    * A (owner) and B (sharer) have **separate** pointers to the actual file F
    * Pros: low overhead
    * Cons: Deletion problem (F is deleted only when no pointers point to it)
  * Symbolic link: `ln -s`
    * can be **file** or **directory**
    * when B tries to share A's F, B creates a special link file G
    * when G is accessed, it will find where F is then access F
    * Thus, if A deletes F, G still exists but doesn't work; if B deletes G, F still exists.
    * Pros: simple deletion
    * Cons: overhead, may result in **general graph** (because it can point to a directory)
* General Graph: not desirable
  * Hard to traverse
  * Need to prevent infinite looping
  * Hard to determine when to remove a file/directory



















