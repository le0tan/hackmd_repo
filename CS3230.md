---
title: CS3230 notes
tags: Module, CS3230
---

# CS3230 notes

Design and Analysis of Algorithms

2020/2021 Semester 1, Divesh Aggarwal

---

## Minimum spanning tree

### Generic greedy algorithm for MST

* Initialize $F=(V,E')$ where $E'$ is empty
* for `i=1 to n-1`
    * Let $C_1,\cdots,c_k$ be the connected components of $F$
    * **Arbitrarily** choose one component $C_j$, pick an edge $e$ with minimum weights among edges **with exactly one endpoint** in $C_j$
    * Add $e$ to $E'$



### Prim's algorithm

Idea: Keep only one connected component $C$, all others are single vertices

Algorithm:
* Keep all edges adjacent to $C$ in a priority queue $Q$
    * extract the min weight edge $(u,v)$, if both endpoints are in $C$, do nothing
    * otherwise, suppose $u$ is in $C$
        * insert $v$ into $C$
        * insert all edges from $v$ into $Q$

Time complexity: $O(m \log m)=O(m \log n)$
* each edge $(u,v)$ can be inserted into $Q$ at most twice (from $u$ and from $v$)
* size of $Q$ is at most $m$ - each insertion/deletion takes $O(\log m)$
* $O(\log m)=O(\log n)$ because $m$ is upper-bounded by $n^2$, $O(\log m)=O(\log n^2)=O(2\log n)=O(\log n)$
* Using Fibonacci heap can be optimized to $O(n\log n + m)$ time

### Kruskal's algorithm

Idea: scan all edges in increasing order of weight. Add the edge if both endpoints are in different components.

#### Union-Find algorithm

`Label[1...n]`, `Count[1...n]`

* `MakeSet(v)`
    * `Label[v]=v`
    * `Count[v]=1`
    * Initialize a list containing `v`
* `Find(v)`
    * return `Label[v]`
* `Union(u,v)`
    * if `Count[u]>Count[v]`, go through all vertices in the list containing $v$, change their label to `Label[u]`
    * vice versa
    * *This step generates a component at least twice as long as the smaller one.*

![](https://i.imgur.com/ZMBxiZS.png)

Time complexity: $O((m+n)\log n)$
* Initial sort of edges: $O(m\log m)=O(m\log n)$
* Each time the component label changes, the corresponding list grows by at least a factor of 2. Therefore each label changes at most $O(\log n)$ times
    * in total $O(n\log n)$ complexity

## Linear sorting

### Comparison-based sorting lower bound

At each of the leaves, we must determine which of the $n!$ permutations is the correct order: $$n! \leq 2^h$$

Using Stirling's approximation, we have $h=\Omega(n\log n)$

### Counting sort

Three arrays
* `A` - array to be sorted
* `B` - result array
* `C` - `C[i]` is the number of elements $\leq i$

```
for i=n to 1:
    B[C[A[i]]] = A[i]
    C[A[i]]-=1
```

Need to fill the numbers from the back to be stable (i.e. if two entries have the same value, their order will not be changed)

Time complexity: $O(n+k)$

### Radix sort

Complexity: $O(d(n+10))=O(dn)$

where $d$ is the maximum count of digits, $10$ means the numbers are 10-based.

### Bucket sort

Complexity: $O(n)$

## DFS/BFS variants in graph problems

Time complexity of DFS/BFS: $O(m+n)$

### DFS variants

* Reachability on a graph
    * `DFS(v)` marks every vertex `u` reachable from `v`, and only those vertices
* Count connected components for undirected graphs
    * can also label connected components
* Tracking traversal order
    * `previsit`: `clock += 1`, `v.pre = clock`
    * `postvisit`: `clock += 1`, `v.post = clock`
    * Lemma 2: For any two vertices $u,v$ in $G$ with v.pre < u.pre, we have the following
        * v.pre < u.pre < u.post < v.post iff DFS(u) is called during the execution of DFS(v) - in other words, v is the ancestor of u in the forest of parent pointers
        * v.pre < v.post < u.pre < u.post, otherwise 
    * Lemma 3: let $u\rightarrow v$ be an edge in the graph, then u.post < v.post implies that the graph must have a path from v to u
    * Corollary 1: for a DAG, for any edge $u\rightarrow v$, v.post < u.post
        * otherwise we have a path from v to u, which forms a cycle
    * Lemma 4 (cycle detection): to check if there exists a cycle, check whether u.post < v.post for some edge u->v
* Topological sort for DAGs
    * $u \prec v$ if there is no path from v to u
    * if u.post > v.post, then there is no path from v to u
    * one such ordering is given by sorting the vertices in reverse order of **post** times
* Longest/shortest path for DAGs
    * Given a DAG $G=(V,E)$, let $s$ be the source vertex
    * shortest: $d(v)=\min_{u\rightarrow v} d(u)+w(u,v)$
        * to get the shortest distance to $v$, we first get the shortest distance to a vertex $u$ that's one-step away from $v$
        * dynamic programming
            * starting from $s$ with $d(s)=0$
            * arrange $v$ in topological order
        * Time complexity: $O(m+n)$
* Strongly connected components
    * two vertices are strongly connected u can reach v and v can reach u
    * a graph is strongly connected iff any pair of vertices are strongly connected
    * Lemma 5: in a DFS execution on $G$, for any strongly connected component $C$ of $G$, exactly one vertex in $C$ does not have a parent in $C$ (either it doesn't have a parent, or has a parent not in $C$)
        * the vertex in $C$ with the smallest v.pre is the **root** of C
    * Lemma 6: the last vertex in any postordering (i.e. sort $v$ w.r.t. v.post) of DFS is a vertex in a source component
        * -> the last vertex in the postordering in rev(G) lies in a sink component of G
    * Algorithm: `SCC(G)`
        * compute rev(G)
        * call DFS(rev(G)) to compute u.post for all vertices u in G
        * call DFS(G) but pick the starting vertex in **decreasing postorder times** computed in the previous step on rev(G)
        * each tree found in the previous step is a strongly connected component

## SSSP algorithms and applications

For unweighted graph: BFS depth is the shortest distance

For weighted graph: Bellman-Ford and Dijkstra
* initialize dist(s)=0, dist(v)=$\infty$ for every other vertex v
* update the distance if we found a shorter path
* store path by pred(v) - the previous vertex of v in the shortest path

**Relax operation**: for an edge u->v, if `dist(v)>dist(u)+w(u,v)`, we can relax `dist(v)` and set `pred(v)` to u.

### Bellman-Ford algorithm

Define dist(v,i) as the shortest distance to v that uses **at most i edges**: $$dist(v,i)=\min (dist(v,i-1), \min_{u:u\rightarrow v\in E}(dist(u,i-1)+w(u\rightarrow v))$$
Initial condition: $dist(v,0)=\infty, dist(s,0)=0$

![](https://i.imgur.com/YICkfYt.png)

**Detecting negative cycle**: run Bellman-Ford once, then run the inner loop one more time to see if we can still relax.

### Dijkstra algorithm

**Idea**: repeatedly find a vertex with the shortest distance so far, relax all its outgoing edges, and not worry about relaxing these edges again - **every edge is relaxed at most once**

![](https://i.imgur.com/2a9jwY0.png)

Time complexity: $O(n\log n + m\log n)$ or $O(n\log n + m)$ (Fibonacci heap)
* $n$ insertions and deletions to the PQ
* every edge is relaxed at most once - $O(m)$ times of updating the priority of a vertex

## APSP

### Re-weighting

Re-weight the graph to avoid negative weights, without changing shortest paths.

* Johnson's idea
    * total weight of any path from $s$ to $t$ changes by the same amount
    * for every vertex $x$, we define a function $f(x)$, reweight edges by
        * $w'(x\rightarrow y)=w(x\rightarrow y)+f(x)-f(y)$
        * for any path from $u$ to $v$, the path cost changes by a constant $f(u)-f(v)$
        * we need to find the function $f$ such that all edges are non-negative
    * Fix a vertex $s$, calculate the shortest distance from $s$ to every vertex $x$ as $dist(x)$ - $dist(x)$ is a suitable function
    * Add a vertex $s$ to the graph, connect $s$ to every other vertex with an edge of weight 0
        * doesn't create new paths

![](https://i.imgur.com/oOAo72h.png)

Total complexity: $O(nm+n^2\log n)$

### Modified Bellman-Ford

Define $dist(u,v,i)$ as the shortest distance from $u$ to $v$ with **at most** $i$ edges

![](https://i.imgur.com/V6t3h97.png)

Complexity: $O(n^2m)$

#### Divide-and-conquer

![](https://i.imgur.com/MYbDE4U.png)

* The shortest distance is given by plugging in $k=\lceil \log_2 n \rceil$
* Complexity: $O(n^3\log n)$
    * $k$ from 1 to $\log n$
    * $v$ and $x$ from 1 to $n$
* Connection to matrix multiplication

### Floyd-Warshall

Define $dist(u,v,r)$ as the shortest distance from $u$ to $v$ that only goes through vertices numbered $1,2,\cdots,r$

![](https://i.imgur.com/EPWeZOA.png)
![](https://i.imgur.com/jkxVHFS.png)

Complexity: $O(n^3)$

## Matrix multiplication

// see the lecture notes

## Randomized algorithms

// see the lecture notes

## NP hardness

### P vs. NP

In this chapter, we focus on **decision problems**: problems that can be answered with yes or no.

* **P**: set of decision problems that can be solved in **polynomial** time
* **NP**: set of decision problems that, if the answer is `Yes`, then there is a *proof* of this fact that can be checked in polynomial time
    * i.e. given a solution, can check its validity in polynomial time

### NP-hard and NP-complete

* **NP-hard**: if $\Pi$ can be solved in polynomial time, then $P=NP$
* **NP-complete**: if it's both NP-hard and NP(-easy)

The Cook-Levin theorem: **Circuit satisfiability** is NP-hard

### Reduction

> To prove that problem $Y$ is NP-hard, reduce a known NP-hard problem $X$ to $Y$

Denote the known NP-hard problem as $X$, follow these steps:
1. Describe a polynomial time algorithm to transform **an arbitrary** instance $x$ of $X$ into a **special** instance $y$ of $Y$
2. Prove if $x$ is `Yes` for $X$, then $y$ is `Yes` for $Y$
3. Prove if $y$ is `Yes` for $Y$, then $x$ is `Yes` for $x$

Mentioned NP-hard problems:
* circuit satisfiability
* 3-SAT
* SAT
* Maximum independent set
    * specifically, whether there exists a IndSet of size $k$ in $G$
    * reduce **3-SAT** to MaxIndSet
* Max clique
    * Clique: a subgraph that's complete
    * reduce MaxIndSet to MaxClique
        * $G$ has an IndSet of size $k$ iff $G'$ has a MaxClique of size $k$
* Min vertex cover
    * Vertex cover: a set of vertices that cover all edges in $G$
    * reduce MaxIndSet to MinVertexCover
        * if $V_1$ is an independent set of $G=(V,E)$, then $V-V_1$ is a vertex cover of $G$
        * i.e. $G$ has an IndSet of size $k$ iff $G$ has a vertex cover of size $n-k$
* 3-coloring
    * $k$-coloring a a graph: using $k$ colors on all vertices, such that every edge has vertices of different colors
* Subset sum
    * Given a set of positive integers $X$ and an integer $T$, determine whether $X$ has a subset whose sum is $T$
    * reduce IndSet to Subset sum
* Partition
    * Given a set of numbers $X$, partition it into $X_1, X_2$ such that their sums are the same
    * reduce subset sum to partition
        * given set $X$ and $T$, construct set $X'=X\cup \{S-2T\}$ where $S$ is the sum of $X$
        * $\Rightarrow$: if $X$ have a subset $X_1$ that sums to $T$, then $X_2=X-X_1$ sums to $S-T$, then $X_3=\{S-2T\}\cup X_1$ sums to $S-T$. Therefore $X_3$ and $X_2$ is a partition of $X'$
        * $\Leftarrow$: if $X'$ has a partition $X_1, X_2$, then one of them contains element $S-2T$, the rest is trivial
* Hamiltonian cycle
    * in a directed graph, a cycle that visits every vertex **exactly once**
* Hamiltonian path
    * in a directed graph, a path that begins with $s$, ends at $t$, and visites every vertex **exactly once**
    * reduce Hamiltonian cycle to Hamiltonian path
* Undirected Hamiltonian cycle
* Undirected Hamiltonian path
* Traveling salesman
    * Given a weighted undirected graph, does there exist a route that visits every city and returns to the origin city with total cost $\leq k$?
    * reduce undirected Hamiltonian cycle to TSP
        * Given a undirected unweighted graph $G$, let $k$=number of vertices in $G$, construct undirected weighted graph $G'$ by assigning cost 1 to every edge in $G$
        * $\Rightarrow$: the Hamiltonian cycle is the route in TSP
        * $\Leftarrow$: the TSP route is a Hamiltonian cycle of $G$
* c-approximate TSP
* Euclidean TSP

## Approximation algorithms





