---
title: CS3243 notes
tags: Module, CS3243
---

# CS3243 notes

## Chapter 3: Solving problems by searching

### 3.3 Searching for solutions

* Frontier:
    * The set of all leaf nodes available for expansion at any given point is called the frontier.
    * or The nodes the we have seen but haven't explored yet
* Tree-search vs. graph-search
    * ![](https://i.imgur.com/vnNLzRK.png)
    * Tree-search can re-visit an expanded node while graph-search can't
* Graph search
    * the search tree contains at most one copy of each state, so we can think of it as growing a tree directly on the **state-space graph**
    * the frontier separates the state-space graph into the explored region and the unexplored region
* Node vs. state
    * A **node** is a bookkeeping data structure used to represent the search tree. 
    * A **state** corresponds to a configuration of the world.

#### 3.3.2 Measuring problem-solving performance

* **Completeness**: Is the algorithm guaranteed to find a solution when there is one?
* **Optimality**: Does the strategy find the optimal solution, as defined on page 68?
* **Time complexity**: How long does it take to find a solution?
* **Space complexity**: How much memory is needed to perform the search?

Complexity is expressed in terms of three quantities: 
* $b$, the branching factor or maximum number of successors of any node; 
* $d$, the depth of the shallowest goal node (i.e., the number of steps along the path from the root); 
* $m$, the maximum length of any path in the state space.

Two types of cost:
* Search cost
* Total cost = search cost + path cost

### 3.4 Uninformed search strategies

Search strategy = the order of expanding the frontier

#### Breadth-first search (BFS)
* expand shallowest unexpanded node
* use a FIFO queue for the frontier
* Complete: Yes (if $b$ is finite)
* Optimal: No (unless step cost === 1)
* Time: $O(b)+O(b^2)+ ... +O(b^d)=O(b^d)$
* Space: = max size of frontier = $O(b^d)$
#### Uniform-cost search (UCS)
* expand least-path-cost unexpanded node
* use a priority queue sorted by path cost $g$ for the frontier
    * equivalent to BFS is all step costs are equal
    * note that the algorithm returns **not** when the goal state is added to the frontiers, it returns when the goal state is the least cost among the frontier and is about to be expanded
* Complete: Yes (if all step costs are $>=\epsilon$)
* Optimal: Yes
* Time: $O(b^{1+\lfloor \dfrac{C^*}{\epsilon} \rfloor})$
    * where $C^*$ is the optimal cost
* Space: $O(b^{1+\lfloor \dfrac{C^*}{\epsilon} \rfloor})$
#### Depth-first search (DFS)
* expand deepest unexpanded node
* use a LIFO queue (stack) for frontier
* Complete: No (if depth is infinite)
* Optimal: No (reason similar to BFS)
* Time: $O(b^m)$
* Space: $O(bm)$ (can be $O(m)$)
    * backtracing search can achieve better space complexity
        * only one successor is pushed into the stack
        * partially expanded node remembers which successor to generate next
#### Depth-limited search (DLS)
* run DFS with limited depth $l$
* Also not complete, not optimal
* Time: $O(b^l)$, space: $O(bl)$
#### Iterative deepening search (IDS)
* perform DLS with increasing $l$ until goal node is found
* better if state space is large and depth is unknown
* ![](https://i.imgur.com/6tlFZMg.png)
* Complete: yes if $d$ is finite
* Optimal: no unless step cost is 1
* Time: $O(b^d)$
* Space: $O(bd)$ can be $O(d)$
#### Summary
![](https://i.imgur.com/ZXhhAPZ.png)

### 3.5 Informed (heuristic) search strategies

#### Best-first search

* Idea: expand node with lowest evaluated cost first
* Implementation:
    * **Evaluation function $f(n)$** for each node
    * Frontier = **priority queue** ordered by nondecreasing cost $f$
    * Skeleton of informed search (i.e. the two algos below are expressing cost evaluation function $f(n)$ in different ways)

#### Greedy best-first search

**Some key conventions:**
* $f(n)$ is the evaluation/**cost function**
* $h(n)$ is the **heuristic function** that estimates the cost of **cheapest path from $n$ to goal state**
* $g(n)$ is the cost of reaching $n$ from start node (actual cost to $n$)

In the case of **greedy** best-first search:
* $f(n) = h(n)$ - use estimated cheapest cost from $n$ to goal state as cost
* expands the node that **appears** to be closest to goal



| Property |  |
| -------- | -------- 
| Completeness | Yes (if $b$ is finite) 
| Optimal | No
| Time | $O(b^m)$, but good heuristic can reduce complexity a lot
| Space | Max size of frontier $O(b^m)

### $A^*$ search

* **Evaluation function** $f(n)=g(n)+h(n)$ = estimated cost of cheapest path **through** $n$ to goal

| Property | |
| -------- | ------- |
| Complete | Yes (if there are finitely many nodes with $f(n) \le f(G)$)
| Optimal | Yes (tree search if $h$ admissible, graph search if $h$ consistent)
| Time | $O(b^{h^*(s_0)-h(s_0)})$ where $s_0$ is the root node, $h^*(s_0)$ is the actual cost from root to goal
| Space | Max size of frontier $O(b^m)$ - all best-first based search share the same space compexity

### 3.6 Heurstic functions

* Admissible
    * $h(n)$ is admissible if it **never overestimates** cost from $n$ to reach goal
    * $\forall n, h(n) \le h^*(n)$ where $h^*(n)$ is the actual cheapest cost from $n$ to goal
    * *Theorem:* If $h(n)$ is admissible, $A^*$ using **tree search** is optimal
        * Assume sub-optimal goal $t$ and optimal goal $t^*$, let $n$ be an unexpanded node on the frontier, on the shortest path to optimal goal $t^*$, we can prove that $n$ is always expanded before expanding $t$ (i.e. it's impossible to reach $t$ before reaching $t^*$)
        * Since we need $n$ to be expanded before $t$, we need $f(n)<f(t)$
        * By the definition of cost function in $A^*$, $g(n)+h(n)<g(t)+h(t)$
        * Since $t$ is already at goal state, $h(t)=0$ -> we need $g(t)>g(n)+h(n)$
        * The relationship between $g(t^*)$ and $g(n)+h(n)$: $g(t^*) \ge g(n)+h(n)$ because an admissible heuristic never overestimates cost
        * Since $t$ is a sub-optimal goal, $g(t)>g(t^*)$ -> $g(t)>g(n)+h(n)$, Q.E.D
* Consistent
    * A heuristic is consistent if for every node $n$ and every successor $n'$ of $n$ generated by any action $a$, we have $h(n) \le c(n,n') + h(n')$
    * *Lemma:* If $h(n)$ is consistent, then for any of its successor $n'$, $f(n')=g(n')+h(n')>=f(n)$
        * $f(n')=g(n')+h(n')=g(n)+c(n,n')+h(n')>=g(n)+c(n,n')+h(n)>=f(n)$
        * $f(n)$ is nondecreasing along any path
        * $A^*$ explores nodes with non-decreasing $f(n)$
            * meaning with a consistent heuristic, it gradually adds "$f-$contours" of nodes
            * ![](https://i.imgur.com/1ZZjHg1.png)
    * *Theorem:* If $h(n)$ is consistent, then $A^*$ using **graph search** is optimal
    * *Claim:* using graph search, and a consistent heuristic, when $A^*$ selects a node $n$ for expansion, the shortest path to $n$ has already been found
        * ![](https://i.imgur.com/A4dHD33.png)
* Admissible vs. Consistent
    * consistent => admissible
        * admissible不一定可以推到consistent
        * i.e. consistency is a stronger sufficient condition than admissibility
        * Example: admissible but not consistent heuristic may result in sub-optimal path using graph search
            * ![](https://i.imgur.com/8JJAVP2.png)
* Deriving admissible heuristics
    * a problem with fewer restrictions - relaxed problem
    * cost of optimal solution to a relaxed problem is an admissible heuristic for the original problem
* Dominance
    * If $h_2(n) \ge h_1(n)$ for all $n$ and both heuristics are admissible, then $h_2$ **dominates** $h_1$ - $h_2$ incurs lower search cost than $h_1$

## Chapter 4: Beyond Classical Search

### 4.1 Local search

* The **path** to goal is irrelevant, the goal state itself is the solution
* State space = set of "complete" configurations
    * find final configuration satisfying constraints
* **Local search**: maintains single *current best* state and try to improve it
    * Advantage: very little memory; find reasonable (not necessarily optimal) solution in a large state space

#### Local search strategies

* **Hill-climbing search**
    * use heuristic function to improve current state
    * ![](https://i.imgur.com/wmuigvz.png)
    * Problems
        * depending on the initial state, can get stuck at *local maxima*
        * non-guaranteed fixes: sideway moves, random restarts

## Chapter 5: Adversarial Search

### 5.1 Games

#### How are games different from normal search problems?

* Solution is a *strategy* mapping every possible opponent response to a move/action
* Unlikely to find optimal solution due to time limit, need to approximate

#### Terminology
* Zero-sum game / completely adversarial game
* Max player: the player that wants to maximize value
* Min player


#### Problem formulation
* Initial state: $s_0$
* States
* Players: `PLAYER(s)` returns which player can move in state `s`
* Actions: `ACTIONS(s)` returns a set of legal moves in state `s`
* Transition model: `RESULT(s,a)` returns the state after action `a` on state `s`
* Terminal test: `TERMINAL(s)` returns true iff `s` is the terminal state
* Utility function: `UTILITY(s,p)` final numerical value for a game that ends in terminal state for player `p` - 在游戏结束的时候玩家`p`赢了（或者亏了）多少钱
    * for a zero-sum game, $\sum_{i=1}^n UTILITY(s_{terminal}, p_i)=0$

#### Player strategy

A strategy $s$ for player $i$: what will $i$ do at **every** node of the tree (states that cannotbe reached included) that they make a move in?

* Winning strategy
* Non-losing strategy
* ![](https://i.imgur.com/ghfKTjA.png)

### 5.2 Optimal decision in games

**Subgame perfect Nash equilibrium**: 

#### Minimax value (of each node)

![](https://i.imgur.com/LBsrTbn.png)

Take the game tree below as an example

![](https://i.imgur.com/hVzklh3.png)

Consider node B, every action $b_i$ will result in a terminal state (i.e. minimax value of the bottom nodes are their utility cost), and since B is a MIN node, it chooses the smallest "reward" out of the three - which is 3, so `MINIMAX(B) = 3`

Intuitively,
* MAX chooses move to maximize the minimum payoff/reward
* MIN chooses move to minimize the maximum payoff/reward

#### Minimax algorithm (backwards induction)

Minimax is effectively DFS...

| Property |  |
| --- | --- |
| Complete | Yes (if game tree is finite)
| Optimal | Yes (optimal gameplay?)
| Time | $O(b^m)$
| Space | Like DFS: $O(bm)$

### 5.3 $\alpha - \beta$ pruning

* Idea: if one node is confirmed to not be able to change the outcome, stop exploring its successors
* For MAX node $n$: $\alpha (n)$=highest **observed** value found on path from $n$, initially $\alpha (n)=-\infty$
* For MIN node $n$: $\beta (n)$=lowest **observed** value found on path from $n$, initially $\beta (n)=+\infty$
* Pruning
    * given a MIN node $n$, stop searching below $n$ if there is some MAX ancestor (not necessarily direct parent, any ancestor) $i$ with $\alpha (i) \ge \beta (n)$
    * given a MAX node $n$, stop searching below $n$ if there is some MIN ancestor $i$ with $\beta (i) \ge \alpha (n)$

**Analysis of $\alpha - \beta$ pruning**
* Perfect ordering: time complexity $O(b^{m/2})$
* Random ordering: $O(b^{\frac{3m}{4}})$ for $b \lt 1000$

![](https://i.imgur.com/XGRu3rO.png)


### 5.4 Imperfect real-time decisions

**Heuristic minimax value**

![](https://i.imgur.com/ASaO3pk.png)

**Cutoff search**

**Run normal minimax until depth $d$ (i.e. until `CUTOFF-TEST(s,d)` returns `True`), then start using evaluation function to choose nodes** - analogous to DLS

Can also be combined with iterative deepening.

### 5.5 Stochastic Games

